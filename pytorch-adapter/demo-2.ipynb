{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14abf9db-91f7-440c-8210-d67b31631a2e",
   "metadata": {},
   "source": [
    "This notebook demonstrates working with object-level annotations via CVAT SDK.\n",
    "It is part of the supplementary materials for the article [\"CVAT SDK PyTorch adapter: using CVAT datasets in your ML pipeline\"](https://www.cvat.ai/post/cvat-sdk-pytorch-adapter).\n",
    "\n",
    "To run it, first fill in your CVAT access credentials in the cell below.\n",
    "You also need to upload the flowers dataset and add some rectangle annotations, as described in the article. Then fill in the training task ID in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c988f-4e9e-47ef-a0af-cca94a90c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVAT_HOST = 'app.cvat.ai' # the hostname of your CVAT instance\n",
    "CVAT_USER = '...' # your username\n",
    "CVAT_PASS = '...' # your password\n",
    "\n",
    "TRAIN_TASK_ID = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fba0e2-297f-4daa-83f5-3dbaeb01bbf7",
   "metadata": {},
   "source": [
    "First, we need to create a CVAT API client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06386c4-9956-44d5-a8c6-2c586435d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "from cvat_sdk import *\n",
    "from cvat_sdk.pytorch import *\n",
    "\n",
    "# configure logging to see what the SDK is doing behind the scenes\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "client = make_client(CVAT_HOST, credentials=(CVAT_USER, CVAT_PASS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb65c31-e282-4f08-a2d3-aa7d7a2c7b26",
   "metadata": {},
   "source": [
    "Now we'll create a `TaskVisionDataset` for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3ef06-f4e0-407a-8125-35f56514c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TaskVisionDataset(client, TRAIN_TASK_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a0b74e-322c-465a-94c4-e60517dcf2b9",
   "metadata": {},
   "source": [
    "Let's examine the sample with the rectangle annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b87fc9-ef72-4878-a3a0-c7c56b3dafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbab8e-c533-490e-8bf2-823f7da71cb1",
   "metadata": {},
   "source": [
    "CVAT SDK provides a lot of information for each annotation.\n",
    "If you just need the basic bounding box & label data,\n",
    "you can use the `ExtractBoundingBoxes` transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45109e40-5c1e-433a-bf62-33fac6e20ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TaskVisionDataset(client, TRAIN_TASK_ID,\n",
    "  target_transform=ExtractBoundingBoxes(\n",
    "    include_shape_types=['rectangle']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d40d2b9-a760-4ed6-a502-cbc094e368c2",
   "metadata": {},
   "source": [
    "With the transform applied, the target component becomes a dictionary\n",
    "suitable for use with the torchvision object detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aedce0-e340-40e9-8589-410589c8b939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
